{
  "master": {
    "tasks": [
      {
        "id": 25,
        "title": "Setup Project Structure and Configuration Management",
        "description": "Create the initial project structure and implement configuration management using YAML for the Bash Daemon Monitor.",
        "details": "1. Create the directory structure as specified in the PRD:\n   ```\n   bamon/\n   ├── bamon                    # Main executable (generated by bashly)\n   ├── bashly.yml              # Bashly configuration\n   ├── src/\n   │   ├── lib/\n   │   │   ├── config.sh       # Configuration management\n   │   │   ├── execution.sh    # Script execution and daemon loop\n   │   │   ├── logging.sh      # Logging functions\n   │   │   ├── sandbox.sh      # Script sandboxing\n   │   │   └── performance.sh  # Performance optimization\n   │   └── *_command.sh        # CLI command implementations\n   ├── config.yaml             # Daemon configuration\n   └── install.sh              # Installation script\n   ```\n2. Set up the Bashly configuration file (bashly.yml) with command structure:\n   - Define all commands: status, add, remove, list, now, start, stop, restart, performance, config\n   - Include subcommands for config: edit, show, validate\n   - Define command options and arguments\n3. Implement the config.sh library for YAML configuration management:\n   - Use 'yq' (version 4.x+) for YAML parsing\n   - Implement functions to read, validate, and write configuration\n   - Create default configuration if none exists\n   - Support environment variable overrides\n4. Create the default config.yaml template with all required sections:\n   - daemon section with default_interval, log_file, pid_file, etc.\n   - sandbox section with timeout, max_cpu_time, etc.\n   - performance section with monitoring settings\n   - scripts section with sample monitoring scripts\n5. Implement configuration validation to ensure all required fields exist\n6. Create helper functions for accessing configuration values throughout the application",
        "testStrategy": "1. Verify the project structure is created correctly\n2. Test configuration loading with valid and invalid YAML files\n3. Verify default configuration is created when none exists\n4. Test configuration validation with missing required fields\n5. Verify environment variable overrides work correctly\n6. Test reading and writing configuration values\n7. Verify the Bashly configuration generates the expected CLI structure\n8. Test the config command and its subcommands",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 26,
        "title": "Implement Logging System and Daemon Process Management",
        "description": "Create the logging system with configurable levels and implement daemon process management functionality.",
        "details": "1. Implement the logging.sh library with the following features:\n   - Support for configurable log levels (DEBUG, INFO, WARN, ERROR)\n   - Log rotation functionality to prevent disk space issues\n   - Functions for logging to both console and file\n   - Timestamp and log level prefixing\n   - Support for redirecting both stdout and stderr to log file in daemon mode\n2. Implement daemon process management:\n   - Create functions to start the daemon in background mode\n   - Implement PID file management for tracking the daemon process\n   - Create stop functionality to terminate the daemon gracefully\n   - Implement restart functionality\n   - Add signal handling for graceful shutdown (SIGTERM, SIGINT)\n3. Set up log file location at ~/.config/bamon/daemon.log (configurable)\n4. Implement foreground mode (without --daemon flag) that outputs to terminal\n5. Create functions to check daemon status (running/stopped)\n6. Implement proper error handling for daemon management operations\n7. Use 'nohup' and output redirection (2>&1) for background operation\n8. Add log rotation based on file size or time interval\n9. Implement log level filtering based on configuration",
        "testStrategy": "1. Test logging at different log levels\n2. Verify log rotation works when log file reaches size limit\n3. Test daemon start in both foreground and background modes\n4. Verify PID file is created and managed correctly\n5. Test daemon stop and verify process is terminated\n6. Test restart functionality\n7. Verify signal handling for graceful shutdown\n8. Test log output redirection in daemon mode\n9. Verify error handling for various failure scenarios\n10. Test log level filtering based on configuration",
        "priority": "high",
        "dependencies": [
          25
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 27,
        "title": "Implement Script Execution and Sandboxing",
        "description": "Create the core script execution engine with sandboxing and resource limits for running monitoring scripts safely.",
        "details": "1. Implement the execution.sh library for script execution:\n   - Create functions to execute bash commands and scripts\n   - Implement interval-based execution scheduling\n   - Add support for different script types (commands, HTTP checks, scripts)\n   - Capture both stdout and stderr from script execution\n   - Track execution time, exit codes, and resource usage\n2. Implement the sandbox.sh library for script isolation:\n   - Use 'timeout' command (from GNU coreutils) for execution time limits\n   - Implement resource limits using ulimit for CPU, memory, and file size\n   - Create temporary directories for script execution\n   - Implement cleanup of temporary resources after execution\n   - Add error detection for various failure types (timeout, memory, permissions)\n3. Create the main daemon loop for continuous monitoring:\n   - Schedule script execution based on configured intervals\n   - Implement non-blocking execution to allow concurrent scripts\n   - Track next execution time for each script\n   - Handle script failures gracefully\n4. Implement execution history storage:\n   - Store execution results in JSON format\n   - Include success/failure status, exit codes, output, timestamps\n   - Implement history retention policy based on configuration\n   - Store history at ~/.config/bamon/execution_history.json (configurable)\n5. Add support for manual execution via 'now' command\n6. Implement concurrent execution management with configurable limits",
        "testStrategy": "1. Test script execution with various script types\n2. Verify resource limits are enforced correctly\n3. Test timeout functionality with long-running scripts\n4. Verify stdout and stderr are captured correctly\n5. Test execution history storage and retrieval\n6. Verify interval-based scheduling works correctly\n7. Test concurrent execution with multiple scripts\n8. Verify cleanup of temporary resources\n9. Test manual execution via 'now' command\n10. Verify error handling for various script failure scenarios\n11. Test history retention policy",
        "priority": "high",
        "dependencies": [
          25,
          26
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 28,
        "title": "Implement Script Management Commands",
        "description": "Create the CLI commands for managing monitoring scripts, including add, remove, list, and status functionality.",
        "details": "1. Implement the add_command.sh for adding new scripts:\n   - Accept script name, command, and interval parameters\n   - Validate input parameters\n   - Add new script to configuration file\n   - Support for enabling/disabling scripts\n   - Handle duplicate script names\n2. Implement the remove_command.sh for removing scripts:\n   - Accept script name parameter\n   - Remove script from configuration\n   - Handle non-existent script names\n3. Implement the list_command.sh for listing scripts:\n   - Display all configured scripts with details\n   - Show enabled/disabled status\n   - Include interval and command information\n   - Support for filtering and sorting options\n4. Implement the now_command.sh for immediate execution:\n   - Execute all scripts immediately\n   - Show execution results\n   - Support for executing specific scripts\n5. Create helper functions for script management operations\n6. Implement validation for script commands and intervals\n7. Add support for script enabling/disabling\n8. Implement proper error handling and user feedback",
        "testStrategy": "1. Test adding scripts with various parameters\n2. Verify duplicate script names are handled correctly\n3. Test removing scripts and verify they're removed from configuration\n4. Verify list command shows all configured scripts\n5. Test immediate execution with 'now' command\n6. Verify validation works for script commands and intervals\n7. Test enabling and disabling scripts\n8. Verify error handling for various failure scenarios\n9. Test with invalid inputs and verify appropriate error messages",
        "priority": "medium",
        "dependencies": [
          25,
          26,
          27
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 29,
        "title": "Implement Status Command with Enhanced Output",
        "description": "Create the status command with comprehensive reporting, including context-aware output display and JSON format support.",
        "details": "1. Implement the status_command.sh with the following features:\n   - Display current status of all monitored scripts\n   - Show success/failure status with clear indicators\n   - Include exit codes, output, execution duration, and timestamps\n   - Support for JSON output format with --json flag\n   - Implement filtering with --failed-only flag\n   - Support for sorting by status, execution time, or script name\n2. Implement context-aware output display:\n   - Show stdout for successful executions\n   - Show intelligent error messages for failures based on error type\n   - Handle timeout, memory, permission, file, and network errors\n   - Implement proper truncation for table view (30 characters)\n   - Show truncation message \"(truncated - use --json)\" for long output\n   - Handle multiline output appropriately\n3. Implement JSON output format:\n   - Include complete execution details without truncation\n   - Proper JSON formatting for multiline output (as array)\n   - Include all metadata (timestamps, duration, exit codes)\n   - No base64 encoding, use proper JSON escaping\n4. Create tabular output format:\n   - Define columns: NAME | STATUS | EXIT CODE | OUTPUT | DURATION | TIME SINCE | NEXT EXECUTION\n   - Implement consistent column widths and alignment\n   - Handle long values with truncation\n   - Use color coding for status (if supported)\n5. Implement intelligent error message generation based on exit codes and output patterns",
        "testStrategy": "1. Test status command with various script states\n2. Verify JSON output format contains complete data\n3. Test output truncation in table view\n4. Verify filtering with --failed-only flag\n5. Test sorting options\n6. Verify intelligent error messages for different failure types\n7. Test with multiline output and verify proper handling\n8. Verify column alignment and truncation in table view\n9. Test with various output lengths and verify consistent truncation\n10. Verify color coding works in supported terminals",
        "priority": "high",
        "dependencies": [
          25,
          26,
          27,
          28
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 30,
        "title": "Implement Performance Optimization and Monitoring",
        "description": "Create the performance monitoring and optimization system to manage system load and resource usage.",
        "details": "1. Implement the performance.sh library with the following features:\n   - System load monitoring using /proc/loadavg or uptime command\n   - CPU, memory, and disk usage tracking\n   - Adaptive scheduling based on system performance\n   - Resource usage tracking per script\n2. Implement the performance_command.sh:\n   - Display system performance metrics\n   - Show optimization status and settings\n   - Include script-specific performance data\n   - Support for enabling/disabling performance optimization\n3. Create concurrent execution management:\n   - Limit number of simultaneously running scripts\n   - Implement queue for scripts when system is at capacity\n   - Add priority scheduling for high-priority scripts\n4. Implement adaptive scheduling:\n   - Adjust execution intervals based on system load\n   - Skip executions during high load periods\n   - Resume normal scheduling when load decreases\n5. Add performance metrics collection:\n   - Track execution times for each script\n   - Monitor success/failure rates\n   - Track resource usage (CPU, memory, time)\n   - Calculate averages and trends\n6. Implement configuration options for performance settings:\n   - load_threshold for determining high load\n   - max_concurrent for limiting simultaneous executions\n   - optimize_scheduling for enabling/disabling optimization",
        "testStrategy": "1. Test system load monitoring under various conditions\n2. Verify concurrent execution limits are enforced\n3. Test adaptive scheduling during high load\n4. Verify performance metrics collection\n5. Test performance command output\n6. Verify queue management for scripts\n7. Test priority scheduling for high-priority scripts\n8. Verify configuration options affect behavior correctly\n9. Test with various system load scenarios\n10. Verify resource usage tracking per script",
        "priority": "medium",
        "dependencies": [
          25,
          26,
          27
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 31,
        "title": "Create Installation Script and Documentation",
        "description": "Develop the installation script for different environments and create comprehensive documentation for the project.",
        "details": "1. Implement the install.sh script with the following features:\n   - Support for user installation (default to ~/.local/bin/)\n   - Support for system installation (with --system flag)\n   - Support for custom installation path (with --prefix flag)\n   - Dependency checking and installation\n   - Configuration directory setup\n   - Sample script installation\n   - PATH setup assistance\n2. Create comprehensive documentation:\n   - README.md with project overview, installation, and usage\n   - Command reference with examples for all commands\n   - Configuration guide with YAML examples\n   - Sample script documentation\n   - Troubleshooting guide\n   - Development setup instructions\n3. Implement platform-specific installation support:\n   - macOS with Homebrew dependencies\n   - Linux with package manager dependencies\n   - WSL2 support\n4. Create man pages for all commands:\n   - Main man page (bamon.1)\n   - Command-specific man pages (bamon-status.1, etc.)\n5. Add installation validation and rollback:\n   - Verify installation was successful\n   - Provide rollback in case of failure\n   - Check for required dependencies\n6. Implement uninstall functionality\n7. Create sample scripts for common monitoring tasks",
        "testStrategy": "1. Test installation on different platforms (macOS, Linux, WSL2)\n2. Verify dependency checking works correctly\n3. Test user, system, and custom installation paths\n4. Verify configuration directory is created correctly\n5. Test PATH setup assistance\n6. Verify sample scripts are installed\n7. Test uninstall functionality\n8. Verify documentation accuracy and completeness\n9. Test installation validation and rollback\n10. Verify man pages are installed correctly",
        "priority": "medium",
        "dependencies": [
          25,
          26,
          27,
          28,
          29,
          30
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 32,
        "title": "Implement CI/CD and Release Automation",
        "description": "Set up GitHub workflows for continuous integration, testing, and automated release management.",
        "details": "1. Create GitHub workflow files:\n   - ci.yml for continuous integration\n   - release.yml for release automation\n2. Implement CI workflow with the following features:\n   - Trigger on commits to main branch\n   - Run tests in Ubuntu container environment\n   - Install dependencies (bash, curl, yq, coreutils)\n   - Execute test suite\n   - Report status to GitHub PR/commit\n3. Implement release workflow:\n   - Manual trigger (workflow_dispatch)\n   - Version detection and bumping\n   - Update version in bashly.yml\n   - Regenerate binary with bashly\n   - Create git tag with new version\n   - Package release assets\n   - Create GitHub release with assets and notes\n4. Implement version management:\n   - Use semantic versioning (MAJOR.MINOR.PATCH)\n   - Automated patch bumping\n   - Git tag format with 'v' prefix (e.g., v0.1.0)\n5. Set up release asset packaging:\n   - Include bamon binary\n   - Include install.sh script\n   - Include documentation and samples\n   - Include tests\n6. Create test environment in Ubuntu container:\n   - Fresh Ubuntu container (latest LTS)\n   - Install dependencies\n   - Run installation script\n   - Execute test suite\n7. Implement BATS (Bash Automated Testing System) tests:\n   - Command functionality tests\n   - Daemon execution tests\n   - Configuration management tests\n   - Performance monitoring tests\n   - Installation tests",
        "testStrategy": "1. Verify CI workflow runs on commits to main branch\n2. Test release workflow with manual trigger\n3. Verify version bumping works correctly\n4. Test binary regeneration with bashly\n5. Verify git tag creation\n6. Test release asset packaging\n7. Verify GitHub release creation\n8. Test in Ubuntu container environment\n9. Verify BATS tests run correctly\n10. Test installation from release assets",
        "priority": "medium",
        "dependencies": [
          25,
          26,
          27,
          28,
          29,
          30,
          31
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 33,
        "title": "Create GitHub Workflows for CI/CD and Release Automation",
        "description": "Implement GitHub Actions workflows for continuous integration testing and automated release management, including version control and asset packaging.",
        "status": "done",
        "dependencies": [
          25,
          31
        ],
        "priority": "high",
        "details": "1. Create the GitHub workflow directory structure:\n   ```\n   .github/\n   └── workflows/\n       ├── ci.yml\n       └── release.yml\n   ```\n\n2. Implement the CI workflow (ci.yml) with the following features:\n   - Configure workflow to trigger on push to main branch and pull requests\n   - Set up Ubuntu latest runner environment\n   - Install required dependencies (bash, curl, yq, jq, coreutils, bats, docker)\n   - Check out repository with fetch-depth: 0 for complete history\n   - Binary generation using bashly\n   - Run container-based tests using Docker\n   - Execute the test suite with proper error reporting (BATS tests + container tests)\n   - Installation script validation\n   - CLI command testing\n   - Cache dependencies to speed up workflow runs\n   - Add status badges to README.md\n\n3. Implement the release workflow (release.yml) with the following features:\n   - Configure manual trigger using workflow_dispatch\n   - Add inputs for version bump type (patch/minor/major)\n   - Add dry run capability for testing\n   - Set up Ubuntu latest runner environment\n   - Install required dependencies (bash, curl, yq, jq, coreutils, bashly)\n   - Check out repository with fetch-depth: 0 for complete history\n   - Implement version detection logic:\n     - Fetch all git tags\n     - Extract highest semantic version tag using `git describe --tags --abbrev=0`\n     - Increment version according to semver rules (patch by default)\n   - Update version in bashly.yml configuration\n   - Regenerate binary using bashly generate\n   - Create git tag with new version\n   - Package release assets:\n     - bamon binary\n     - install.sh script\n     - docs/ directory\n     - samples/ directory\n     - tests/ directory\n   - Create GitHub release with all assets\n   - Push changes back to repository\n\n4. Add GitHub token permissions configuration:\n   - contents: write (for creating releases and tags)\n   - packages: read (for dependency access)\n   - actions: read (for workflow runs)\n\n5. Implement error handling and notifications:\n   - Add failure notifications via GitHub notifications\n   - Implement detailed error reporting in workflow logs\n   - Add retry logic for network-dependent steps\n\n6. Document workflows in README.md:\n   - Add section explaining CI/CD process\n   - Include instructions for manual release triggering\n   - Document version bumping process",
        "testStrategy": "1. Test CI workflow functionality:\n   - Make a test commit to main branch and verify workflow triggers automatically\n   - Create a pull request and confirm tests run on PR\n   - Intentionally break a test and verify the workflow fails appropriately\n   - Check that status badges update correctly\n   - Verify binary generation works correctly\n   - Test installation script validation\n   - Confirm CLI command testing works as expected\n\n2. Test release workflow functionality:\n   - Manually trigger the release workflow with patch version bump\n   - Test the dry run capability to verify workflow without creating actual releases\n   - Verify version detection correctly identifies the highest existing tag\n   - Confirm version in bashly.yml is updated correctly\n   - Validate that binary is regenerated with updated version\n   - Check that git tag is created with correct version format (v1.2.3)\n   - Verify all required assets are included in the GitHub release\n   - Test downloading assets from the release and verify integrity\n\n3. Test error handling:\n   - Simulate network failure during dependency installation\n   - Verify retry logic works as expected\n   - Test with invalid version format and verify appropriate error message\n\n4. Test permissions and security:\n   - Verify workflow runs with minimal required permissions\n   - Confirm secure handling of GitHub token\n   - Test that workflow cannot be triggered by unauthorized users\n\n5. Test in different environments:\n   - Verify release assets work on Ubuntu, macOS, and WSL2\n   - Test installation script from release assets\n   - Validate documentation accuracy for release process",
        "subtasks": [
          {
            "id": 1,
            "title": "Create GitHub workflows directory structure",
            "description": "Set up the .github/workflows/ directory structure for CI and release workflows",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement CI workflow (ci.yml)",
            "description": "Create the continuous integration workflow with automatic triggers, dependency installation, test execution, and error handling",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Implement Release workflow (release.yml)",
            "description": "Create the release automation workflow with version bumping, asset packaging, and GitHub release creation",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Test workflows in GitHub Actions",
            "description": "Verify both CI and release workflows function correctly in the GitHub Actions environment",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Verify version bumping logic",
            "description": "Test the semantic versioning bump logic for patch, minor, and major versions",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Test release asset creation and upload",
            "description": "Verify all release assets are correctly packaged and uploaded to GitHub releases",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Update README.md with CI/CD documentation",
            "description": "Add documentation about the CI/CD process, release automation, and installation instructions using the latest release",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-09-12T23:10:00.761Z",
      "updated": "2025-09-21T20:08:31.140Z",
      "description": "Tasks for master context"
    }
  }
}